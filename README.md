# QXS-SAROPT
QXS-SAROPT Dataset

![Image text](https://github.com/yaoxu008/QXS-SAROPT/blob/main/QXSLAB-SAROPT.png)


[Links to download the data](https://www.wenjuan.com/s/UZBZJv5GwL/)

Deep learning techniques have made an increasing impact on the field of remote sensing. However, deep neural networks based fusion of multimodal data from different remote
sensors with heterogenous characteristics has not been fully explored, due to the lack of availability of big amounts of perfectly aligned multi-sensor image data with diverse scenes of high resolutions, especially for synthetic aperture radar (SAR) data and optical imagery. To promote the development of deep learning based SAR-optical fusion approaches, we release the QXS-SAROPT dataset, which contains 20,000 pairs of SAR-optical image patches. We obtain the SAR patches from SAR satellite GaoFen-3 images and the optical patches from Google Earth. These images cover three port cities: San Diego, Shanghai and Qingdao. Here, we present a detailed introduction of the construction of the dataset, and show its two representative exemplary applications, namely SAR-optical image matching and SAR ship detection boosted by cross-modal information from optical images. As a large open SAR-optical dataset with multiple scenes of a high resolution, we believe QXS-SAROPT will be of potential value for further research in SAR-optical data fusion
technology based on deep learning.

[The QXS-SAROPT Dataset for Deep Learning in SAR-Optical Data Fusion](https://arxiv.org/pdf/2103.08259.pdf)

This paper must be cited when the dataset is used for research purposes.
